{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29df1566",
   "metadata": {},
   "source": [
    "# Test 4 - Comparison vs FM paper: CoinCollector, CookingGame, TreasureHunter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccc2ada6-c297-436f-a4ea-c7ecda7b442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! tar czf Testing.tar *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55cbbde-d821-4fa0-ac9e-18fde6c19c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7772dae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textworld\n",
    "import textworld.gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7f88b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d22da",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textworld'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      2\u001b[39m sys.path.append(\u001b[33m\"\u001b[39m\u001b[33m../Self_evaluation\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mself_evaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m play, LLMAgentSelfEvaluate\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Greg\\Desktop\\Tesi\\LLMs-Play-Textual-Games\\Code\\Testing\\../Self_evaluation\\self_evaluation.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtextworld\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtextworld\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgym\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# %%\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'textworld'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../Self-evaluation\")\n",
    "\n",
    "from self_evaluation import play, LLMAgentSelfEvaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa9f3f",
   "metadata": {},
   "source": [
    "## Game generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984a99d4",
   "metadata": {},
   "source": [
    "Idea:\n",
    "- two models used: no-think and 10-think\n",
    "- different difficulty levels: 6 for coin collector, 5 for common sense, 5 for cooking, 8 for treasure hunter\n",
    "- 5 episodes per case (vs 40 in FM paper)\n",
    "- total episodes: 240 (190 without commonsense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df11440-0b59-4f09-9eb8-abcfb64dc88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tw-make tw-coin_collector --seed 1 --level 1 --output games/coin/seed1-level1.z8\n",
    "!tw-make tw-coin_collector --seed 1 --level 2 --output games/coin/seed1-level2.z8\n",
    "!tw-make tw-coin_collector --seed 1 --level 3 --output games/coin/seed1-level3.z8\n",
    "!tw-make tw-coin_collector --seed 1 --level 4 --output games/coin/seed1-level4.z8\n",
    "!tw-make tw-coin_collector --seed 1 --level 5 --output games/coin/seed1-level5.z8\n",
    "!tw-make tw-coin_collector --seed 1 --level 6 --output games/coin/seed1-level6.z8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45223baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tw-make tw-cooking --seed 1 --level 1 --output games/cooking/seed1-level1.z8\n",
    "!tw-make tw-cooking --seed 1 --level 2 --output games/cooking/seed1-level2.z8\n",
    "!tw-make tw-cooking --seed 1 --level 3 --output games/cooking/seed1-level3.z8\n",
    "!tw-make tw-cooking --seed 1 --level 4 --output games/cooking/seed1-level4.z8\n",
    "!tw-make tw-cooking --seed 1 --level 5 --output games/cooking/seed1-level5.z8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9903c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tw-make tw-treasure_hunter --seed 1 --level 1 --output games/treasure/seed1-level1.z8\n",
    "!tw-make tw-treasure_hunter --seed 1 --level 2 --output games/treasure/seed1-level2.z8\n",
    "!tw-make tw-treasure_hunter --seed 1 --level 3 --output games/treasure/seed1-level3.z8\n",
    "!tw-make tw-treasure_hunter --seed 1 --level 4 --output games/treasure/seed1-level4.z8\n",
    "!tw-make tw-treasure_hunter --seed 1 --level 5 --output games/treasure/seed1-level5.z8\n",
    "!tw-make tw-treasure_hunter --seed 1 --level 6 --output games/treasure/seed1-level6.z8\n",
    "!tw-make tw-treasure_hunter --seed 1 --level 7 --output games/treasure/seed1-level7.z8\n",
    "!tw-make tw-treasure_hunter --seed 1 --level 8 --output games/treasure/seed1-level8.z8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb2e40c",
   "metadata": {},
   "source": [
    "## Game running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99f1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_think_indices = [0, 10]\n",
    "levels = {\"coin\": 6, \"cooking\": 5, \"treasure\": 8}\n",
    "n_episodes = 5\n",
    "max_steps = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97f4686d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('coin', 6), ('cooking', 5), ('treasure', 8)]\n"
     ]
    }
   ],
   "source": [
    "zipped_levels = list(zip(levels.keys(), levels.values()))\n",
    "print(zipped_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f6fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in n_think_indices:\n",
    "    for game_name in levels.keys():\n",
    "        for level in levels[game_name]:\n",
    "            results = play(LLMAgentSelfEvaluate(selfeval_turns=n, verbose=False),\n",
    "                        f\"games/{game_name}/seed1-level{level}\", max_steps=max_steps,  n_episodes=n_episodes)\n",
    "            with open(f'./Testing 4/{n}think_{game_name}_level{level}.pickle', 'wb') as f:\n",
    "                pickle.dump(results, f)\n",
    "                print(\"Data pickled.\")\n",
    "                f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5098ee46-5dff-41fb-adb4-1851b318ea84",
   "metadata": {},
   "source": [
    "# Data aggregation for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e07c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_nothink = np.array()\n",
    "coin_10think = np.array()\n",
    "treasure_nothink = np.array()\n",
    "treasure_10think = np.array()\n",
    "cooking_nothink = np.array()\n",
    "cooking_10think = np.array()\n",
    "\n",
    "for n in n_think_indices:\n",
    "    for read_bool in (True, False):\n",
    "        avg_final_score = 0\n",
    "        final_scores = []\n",
    "        for seed in seeds:\n",
    "            results = []\n",
    "            with open(f'./Testing 3/{n}think_{\"blind_\" if not read_bool else \"\"}_seed{seed}.pickle', 'rb') as f:\n",
    "                pickle.load(results, f)\n",
    "                print(\"Data pickled.\")\n",
    "                f.close()\n",
    "            final_scores.append(results[0][-1][1] / max_scores[seeds.index(seed)]) # run 1, last step, score normalized\n",
    "\n",
    "        avg_final_score = np.mean(final_scores)\n",
    "        bootstrap_results = bootstrap(data=(final_scores,), \n",
    "                              statistic=np.mean,\n",
    "                              method=\"basic\",\n",
    "                              n_resamples=1000,\n",
    "                              confidence_level=0.9)\n",
    "        if read_bool:\n",
    "            avg_final_scores.append(avg_final_score)\n",
    "            avg_final_scores_ci.append((bootstrap_results.confidence_interval.high, bootstrap_results.confidence_interval.low)) \n",
    "        else:\n",
    "            avg_final_scores_blind.append(avg_final_score)\n",
    "            avg_final_scores_blind_ci.append((bootstrap_results.confidence_interval.high, bootstrap_results.confidence_interval.low)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3085eb",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59179ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(10,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d31c2d-b310-4c22-89e1-550cd0b924c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = n_think_indices # n-think\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "ax.plot(n, avg_final_scores, label=\"non-ephemeral self-evaluation\", marker=\".\", linestyle=\"-\", color=\"red\")\n",
    "ax.plot(n, avg_final_scores_blind, label=\"ephemeral self-evaluation\", marker=\".\", linestyle=\"-\", color=\"blue\")\n",
    "\n",
    "ax.fill_between(n,\n",
    "                np.clip([i[0] for i in avg_final_scores_ci], 0, 1),\n",
    "                np.clip([i[1] for i in avg_final_scores_ci], 0, 1),\n",
    "                alpha=0.1, color=\"red\")\n",
    "ax.fill_between(n,\n",
    "                np.clip([i[0] for i in avg_final_scores_blind_ci], 0, 1),\n",
    "                np.clip([i[1] for i in avg_final_scores_blind_ci], 0, 1),\n",
    "                alpha=0.1, color=\"blue\")\n",
    "\n",
    "\n",
    "ax.set_title(\"Average final score of an ephemeral/non-ephemeral $n$-think model with $n=0,...,10$\")\n",
    "ax.set_xlabel('n (number non-self-evaluating turns for every self-evaluating turn)')\n",
    "ax.set_ylabel('average final score, normalized')\n",
    "\n",
    "gridlines = np.arange(n[0], n[-1]+1, 1)\n",
    "ax.set_xticks(gridlines)\n",
    "ax.grid(axis=\"x\", alpha=0.2)\n",
    "\n",
    "# ax.set_ylim(0.2, 1.1)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
