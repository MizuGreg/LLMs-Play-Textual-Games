{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29df1566",
   "metadata": {},
   "source": [
    "# Experiment 5 - Ephemerality in complex games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc2ada6-c297-436f-a4ea-c7ecda7b442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! tar czf Experiments.tar *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55cbbde-d821-4fa0-ac9e-18fde6c19c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7f88b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529d22da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c487820c0f5419f9008d6363c574d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../Self-evaluation\")\n",
    "\n",
    "from self_evaluation import play, LLMAgentSelfEvaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa9f3f",
   "metadata": {},
   "source": [
    "# Notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb5f038-dce9-4c77-bc16-20d954c477d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_number = 5\n",
    "\n",
    "seeds = range(1,51)\n",
    "n_episodes = 1\n",
    "max_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c3a9e9-f154-4856-ab6c-98ca6ba78101",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./Experiment 1/max_scores.pickle\", \"rb\") as f:\n",
    "    max_scores_simple = pickle.load(f)\n",
    "    print(\"Data loaded.\")\n",
    "\n",
    "max_scores_simple = max_scores_simple[:len(seeds)]\n",
    "max_score_cooking = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb2e40c",
   "metadata": {},
   "source": [
    "## Game running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_think_indices = [4, 10]\n",
    "n_episodes = 1\n",
    "max_steps = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02d1ee",
   "metadata": {},
   "source": [
    "### 0 and e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a4cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are not needed\n",
    "game = \"simple\"\n",
    "\n",
    "results_all_seeds = []\n",
    "for seed in seeds:\n",
    "    results = play(LLMAgentSelfEvaluate(selfeval_turns=0,\n",
    "                                        verbose=False,\n",
    "                                        log=f\"./Experiment {exp_number}/logs/{game}/0think-seed{seed}.log\"\n",
    "                                        ),\n",
    "                    f\"games/{game}/seed{seed}.z8\",\n",
    "                    max_steps=max_steps,\n",
    "                    n_episodes=n_episodes)\n",
    "    results_all_seeds.append(results[0]) # only one episode\n",
    "with open(f\"./Experiment {exp_number}/0think_{game}.pickle\", \"wb\") as f:\n",
    "    pickle.dump(results_all_seeds, f) # so we dump already with grouping by seed!!\n",
    "    print(\"Data pickled.\")\n",
    "\n",
    "results_all_seeds = []\n",
    "for seed in seeds:\n",
    "    results = play(LLMAgentSelfEvaluate(selfeval_turns=1,\n",
    "                                        reads_own_reasoning=False,\n",
    "                                        verbose=False,\n",
    "                                        log=f\"./Experiment {exp_number}/logs/{game}/e1think-seed{seed}.log\"\n",
    "                                        ),\n",
    "                    f\"games/{game}/seed{seed}.z8\",\n",
    "                    max_steps=max_steps,\n",
    "                    n_episodes=n_episodes)\n",
    "    results_all_seeds.append(results[0]) # only one episode\n",
    "with open(f\"./Experiment {exp_number}/e1think_{game}.pickle\", \"wb\") as f:\n",
    "    pickle.dump(results_all_seeds, f) # so we dump already with grouping by seed!!\n",
    "    print(\"Data pickled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236efc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = \"cooking\"\n",
    "\n",
    "results_all_seeds = []\n",
    "for seed in seeds:\n",
    "    results = play(LLMAgentSelfEvaluate(selfeval_turns=0,\n",
    "                                        verbose=False,\n",
    "                                        log=f\"./Experiment {exp_number}/logs/{game}/0think-level1-seed{seed}.log\"\n",
    "                                        ),\n",
    "                    f\"games/{game}/level1-seed{seed}.z8\",\n",
    "                    max_steps=max_steps,\n",
    "                    n_episodes=n_episodes)\n",
    "    results_all_seeds.append(results[0]) # only one episode\n",
    "with open(f\"./Experiment {exp_number}/0think_{game}.pickle\", \"wb\") as f:\n",
    "    pickle.dump(results_all_seeds, f)\n",
    "    print(\"Data pickled.\")\n",
    "\n",
    "results_all_seeds = []\n",
    "for seed in seeds:\n",
    "    results = play(LLMAgentSelfEvaluate(selfeval_turns=1,\n",
    "                                        reads_own_reasoning=False,\n",
    "                                        verbose=False,\n",
    "                                        log=f\"./Experiment {exp_number}/logs/{game}/e1think-level1-seed{seed}.log\"\n",
    "                                        ),\n",
    "                    f\"games/{game}/level1-seed{seed}.z8\",\n",
    "                    max_steps=max_steps,\n",
    "                    n_episodes=n_episodes)\n",
    "    results_all_seeds.append(results[0]) # only one episode\n",
    "with open(f\"./Experiment {exp_number}/e1think_{game}.pickle\", \"wb\") as f:\n",
    "    pickle.dump(results_all_seeds, f)\n",
    "    print(\"Data pickled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e3ca71",
   "metadata": {},
   "source": [
    "### The others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431cac4a-4626-4c00-b2fd-b59946b30efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "game = \"simple\"\n",
    "\n",
    "for n in n_think_indices:\n",
    "    for ephemeral in [False, True]:\n",
    "        results_all_seeds = []\n",
    "        for seed in seeds:\n",
    "            results = play(LLMAgentSelfEvaluate(selfeval_turns=n,\n",
    "                                                reads_own_reasoning=ephemeral,\n",
    "                                                random_selfeval=True,\n",
    "                                                verbose=False,\n",
    "                                                log=f\"./Experiment {exp_number}/logs/{game}/{'e' if ephemeral else ''}r{n}think-seed{seed}.log\"\n",
    "                                                ),\n",
    "                            f\"games/{game}/seed{seed}.z8\", max_steps=max_steps, n_episodes=n_episodes)\n",
    "            results_all_seeds.append(results[0]) # only one episode\n",
    "        with open(f\"./Experiment {exp_number}/{'e' if ephemeral else ''}r{n}think_{game}.pickle\", \"wb\") as f:\n",
    "            pickle.dump(results_all_seeds, f)\n",
    "            print(\"Data pickled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7243bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = \"cooking\"\n",
    "\n",
    "for n in n_think_indices:\n",
    "    for ephemeral in [False, True]:\n",
    "        results_all_seeds = []\n",
    "        for seed in seeds:\n",
    "            results = play(LLMAgentSelfEvaluate(selfeval_turns=n,\n",
    "                                                reads_own_reasoning=ephemeral,\n",
    "                                                random_selfeval=True,\n",
    "                                                verbose=False,\n",
    "                                                log=f\"./Experiment {exp_number}/logs/{game}/{'e' if ephemeral else ''}r{n}think-level1-seed{seed}.log\"\n",
    "                                                ),\n",
    "                            f\"games/{game}/level1-seed{seed}.z8\", max_steps=max_steps, n_episodes=n_episodes)\n",
    "            results_all_seeds.append(results[0]) # only one episode\n",
    "        with open(f\"./Experiment {exp_number}/{'e' if ephemeral else ''}r{n}think_{game}_level1.pickle\", \"wb\") as f:\n",
    "            pickle.dump(results_all_seeds, f)\n",
    "            print(\"Data pickled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5098ee46-5dff-41fb-adb4-1851b318ea84",
   "metadata": {},
   "source": [
    "# Data aggregation for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.stats import bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_arrays = {\"simple\": [], \"cooking\": []}\n",
    "\n",
    "# 0/e1\n",
    "\n",
    "with open(f\"./Experiment {exp_number}/0think_simple.pickle\", \"rb\") as f:\n",
    "    results_all_seeds = pickle.load(f)\n",
    "final_scores = [run[-1][1] for run in results_all_seeds]\n",
    "final_scores_normalized = np.array(final_scores) / np.array(max_scores_simple)\n",
    "final_arrays[\"simple\"].append(final_scores_normalized)\n",
    "with open(f\"./Experiment {exp_number}/e1think_simple.pickle\", \"rb\") as f:\n",
    "    results_all_seeds = pickle.load(f)\n",
    "final_scores = [run[-1][1] for run in results_all_seeds]\n",
    "final_scores_normalized = np.array(final_scores) / np.array(max_scores_simple)\n",
    "final_arrays[\"simple\"].append(final_scores_normalized)\n",
    "\n",
    "with open(f\"./Experiment {exp_number}/0think_cooking_level1.pickle\", \"rb\") as f:\n",
    "    results_all_seeds = pickle.load(f)\n",
    "final_scores = [run[-1][1] for run in results_all_seeds]\n",
    "final_scores_normalized = np.array(final_scores) / max_score_cooking\n",
    "final_arrays[\"cooking\"].append(final_scores_normalized)\n",
    "with open(f\"./Experiment {exp_number}/e1think_cooking_level1.pickle\", \"rb\") as f:\n",
    "    results_all_seeds = pickle.load(f)\n",
    "final_scores = [run[-1][1] for run in results_all_seeds]\n",
    "final_scores_normalized = np.array(final_scores) / max_score_cooking\n",
    "final_arrays[\"cooking\"].append(final_scores_normalized)\n",
    "\n",
    "# simple 4/12\n",
    "for n in n_think_indices:\n",
    "    for ephemeral in [False, True]:\n",
    "        results_all_seeds = []\n",
    "        with open(f\"./Experiment {exp_number}/{'e' if ephemeral else ''}r{n}think_simple.pickle\", \"rb\") as f:\n",
    "            results_all_seeds = pickle.load(f)\n",
    "        final_scores = [run[-1][1] for run in results_all_seeds]\n",
    "        final_scores_normalized = np.array(final_scores) / np.array(max_scores_simple)\n",
    "        final_arrays[\"simple\"].append(final_scores_normalized)\n",
    "\n",
    "# cooking 4/12\n",
    "for n in n_think_indices:\n",
    "    for ephemeral in [False, True]:\n",
    "        results_all_seeds = []\n",
    "        with open(f\"./Experiment {exp_number}/{'e' if ephemeral else ''}r{n}think_cooking_level1.pickle\", \"rb\") as f:\n",
    "            results_all_seeds = pickle.load(f)\n",
    "        final_scores = [run[-1][1] for run in results_all_seeds]\n",
    "        final_scores_normalized = np.array(final_scores) / max_score_cooking\n",
    "        final_arrays[\"cooking\"].append(final_scores_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3085eb",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59179ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(12,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d31c2d-b310-4c22-89e1-550cd0b924c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors3 = ['#4c72b0', '#dd8452', '#55a868', '#c44e52', '#8172b3', '#937860', '#da8bc3', '#8c8c8c', '#ccb974', '#64b5cd'] #matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433195fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_palette1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0baa6e-3345-413a-829c-9d602a8904d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "data_combined = []\n",
    "for key in final_arrays.keys():\n",
    "    for array in final_arrays[key]:\n",
    "        data_combined = np.concatenate(data_combined, array)\n",
    "array_length = len(final_arrays[\"simple\"][0])\n",
    "\n",
    "# only for reference\n",
    "grouping_labels = [\"Simple\", \"Cooking\"] \n",
    "subgrouping_labels = [\"0-think\", \"e1-think\", \"4-think\", \"e4-think\", \"12-think\", \"e12-think\"]\n",
    "\n",
    "grouping = [\"Simple\"] * len(final_arrays[\"simple\"])*array_length + [\"Cooking\"] * len(final_arrays[\"simple\"])*array_length\n",
    "subgrouping = ([\"0-think\"] * array_length + [\"e1-think\"] * array_length + [\"4-think\"] * array_length + [\"e4-think\"] * array_length + [\"12-think\"] * array_length + [\"e12-think\"] * array_length) * 2\n",
    "\n",
    "swarm = sns.swarmplot(\n",
    "    x=grouping, hue=subgrouping, y=data_combined,\n",
    "    ax=ax,\n",
    "    palette=custom_palette2,\n",
    "    size=3,\n",
    "    dodge=True,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "box = sns.boxplot(x=grouping, hue=subgrouping, y=data_combined,\n",
    "                  boxprops={\"alpha\": 0.1},\n",
    "                  showfliers=False,\n",
    "                  width=0.8, gap=0.2,\n",
    "                  palette=custom_palette1,\n",
    "                  showmeans=True,\n",
    "                  medianprops={\"color\": \"black\", \"linewidth\": 2, \"alpha\": 0.5},\n",
    "                  legend=True\n",
    "                  )\n",
    "\n",
    "scatter1 = sns.swarmplot(x=grouping_means_medians, hue=subgrouping_medians, y=medians,\n",
    "                        legend=True,\n",
    "                        dodge=True,\n",
    "                         palette=custom_palette3,\n",
    "                         marker=\"X\",\n",
    "                         size=10\n",
    "                        )\n",
    "scatter1 = sns.swarmplot(x=grouping_means_medians, hue=subgrouping_means, y=means,\n",
    "                        legend=True,\n",
    "                        dodge=True,\n",
    "                        palette=custom_palette3,\n",
    "                         marker=\"^\",\n",
    "                         size=10\n",
    "                        )\n",
    "\n",
    "# ax.set_title(f\"Score comparison between fixed and random $n$-think\")\n",
    "ax.set_ylabel(\"normalized final score\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
