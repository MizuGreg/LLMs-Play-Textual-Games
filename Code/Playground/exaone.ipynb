{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30d78b03",
   "metadata": {},
   "source": [
    "# ExaOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textworld\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b18c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import accelerate\n",
    "torch.set_default_device('cuda')\n",
    "torch.cuda.device(\"cuda\")\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc5582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca1209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.hf_device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e934481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Shortly explain what Zork is.\"  # English example\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \n",
    "     \"content\": \"You are EXAONE model from LG AI Research, a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "output = model.generate(\n",
    "    input_ids.to(\"cuda\"),\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_new_tokens=200,\n",
    "    do_sample=False,\n",
    ")\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0006f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "prompt = \"Explain what Zork is in one single sentence.\"  # English example\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \n",
    "     \"content\": \"You are EXAONE model from LG AI Research, a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "output = model.generate(\n",
    "    input_ids.to(\"cuda\"),\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_new_tokens=200,\n",
    "    do_sample=False,\n",
    ")\n",
    "print(tokenizer.decode(output[0]))\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Inference took {(end - start):.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f55d82",
   "metadata": {},
   "source": [
    "## Context size and shifting window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb13705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
