{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30d78b03",
   "metadata": {},
   "source": [
    "# ExaOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import textworld\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b18c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import accelerate\n",
    "torch.set_default_device('cuda')\n",
    "torch.cuda.device(\"cuda\")\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc5582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca1209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.hf_device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0006f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain what Zork is in one single sentence.\"  # English example\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \n",
    "     \"content\": \"You are EXAONE model from LG AI Research, a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "output = model.generate(\n",
    "    input_ids.to(\"cuda\"),\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_new_tokens=200,\n",
    "    do_sample=False,\n",
    ")\n",
    "print(tokenizer.decode(output[0]))\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Inference took {(end - start):.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f55d82",
   "metadata": {},
   "source": [
    "## Context size and shifting window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb13705",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_system = \"[|system|]\"\n",
    "token_endofturn = \"[|endofturn|]\"\n",
    "token_user = \"[|user|]\"\n",
    "token_assistant = \"[|assistant|]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"Downloading zork1.z5 ...\"\n",
    "!wget -q -N https://archive.org/download/Zork1Release88Z-machineFile/zork1.z5\n",
    "!echo \"Done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05a5bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let the environment know what information we want as part of the game state.\n",
    "infos = textworld.EnvInfos(\n",
    "    feedback=True,    # Response from the game after typing a text command.\n",
    "    description=True, # Text describing the room the player is currently in.\n",
    "    inventory=True    # Text describing the player's inventory.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d183eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = textworld.start('./zork1.z5', request_infos=infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ce567",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant playing a textual game. You analyze the information given carefully and reply exclusively in the form \\\"verb noun\\\", e.g. \\\"open box\\\" or \\\"take key\\\".\"\n",
    "context = token_system + system_prompt + token_endofturn\n",
    "\n",
    "try:\n",
    "    done = False\n",
    "    env.reset()\n",
    "    while not done:\n",
    "        game_status = env.render(mode=\"text\")\n",
    "        print(game_status)\n",
    "        context += token_user + game_status + token_assistant\n",
    "        \n",
    "        start = time.time()    \n",
    "        input_ids = tokenizer.encode(\n",
    "            context,\n",
    "            return_tensors=\"pt\")\n",
    "        \n",
    "        output = model.generate(\n",
    "            input_ids.to(\"cuda\"),\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False)\n",
    "\n",
    "        response = tokenizer.decode(output[0, input_ids.shape[1]:])\n",
    "        context += response\n",
    "        print(response.split(\"[\")[0])\n",
    "        reply = re.sub('\\W+',' ', response.split(\"[\")[0]) # # remove token endofturn and potential unwanted characters, like quotes\n",
    "        \n",
    "        end = time.time()\n",
    "        print(f\"Inference took {(end - start):.3f} seconds\")\n",
    "        \n",
    "        command = reply if len(reply.split()) <= 4 else \"look around\"\n",
    "        game_state, reward, done = env.step(command)\n",
    "\n",
    "    env.render()  # Final message.\n",
    "except KeyboardInterrupt:\n",
    "    pass  # Quit the game.\n",
    "\n",
    "print(\"Played {} steps, scoring {} points.\".format(game_state.moves, game_state.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f148a3",
   "metadata": {},
   "source": [
    "Next: use the notebook `Playing TextWorld generated games with OpenAI Gym.ipynb`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
