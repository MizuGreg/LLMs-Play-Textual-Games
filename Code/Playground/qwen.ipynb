{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30d78b03",
   "metadata": {},
   "source": [
    "# Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e8f21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import textworld\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "966b18c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import accelerate\n",
    "torch.set_default_device('cuda')\n",
    "torch.cuda.device(\"cuda\")\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c02a89bf-fdc4-4a35-b4d0-22b230ecdc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c1b89de8e44a0f84580d43fbfc5368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen3-1.7B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eca1209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model.embed_tokens': 0, 'lm_head': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 0, 'model.layers.20': 0, 'model.layers.21': 0, 'model.layers.22': 0, 'model.layers.23': 0, 'model.layers.24': 'cpu', 'model.layers.25': 'cpu', 'model.layers.26': 'cpu', 'model.layers.27': 'cpu', 'model.norm': 'cpu', 'model.rotary_emb': 'cpu'}\n"
     ]
    }
   ],
   "source": [
    "print(model.hf_device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07285302-a27f-4f24-9dff-91e0ba5e7b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "think_command_id = 151668"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f206ab06-c9f9-4eb0-9ff1-547dcc7c725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(inference took 5.292 seconds)\n",
      "thinking content: \n",
      "content: The optimal strategy for winning Space Invaders is to shoot the invaders when they are in the top row, avoid being hit by their fire, and shoot them when they are in the middle of their formation to maximize damage while minimizing risk.\n"
     ]
    }
   ],
   "source": [
    "# prepare the model input\n",
    "prompt = \"Explain what the optimal strategy for winning Space Invaders is in one sentence.\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "start = time.time()\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=32000\n",
    ")\n",
    "end = time.time()\n",
    "print(f\"(inference took {(end - start):.3f} seconds)\")\n",
    "\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # index finding </think>\n",
    "    index = len(output_ids) - output_ids[::-1].index(think_command_id)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33550f55-c5df-4b15-9191-89d8778732b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Explain what the optimal strategy for winning Space Invaders is in one sentence.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "The optimal strategy for winning Space Invaders is to shoot the invaders when they are in the top row, avoid being hit by their fire, and shoot them when they are in the middle of their formation to maximize damage while minimizing risk.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(generated_ids[0], skip_special_tokens = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc161107-00b1-4997-bc60-007808c1fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f55d82",
   "metadata": {},
   "source": [
    "## Context size and shifting window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cb13705",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_system = \"<|im_start|>system\\n\"\n",
    "token_endofturn = \"<|im_end|>\"\n",
    "token_user = \"<|im_start|>user\\n\"\n",
    "token_assistant = \"<|im_start|>assistant\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a776f233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed: 123\n",
      "Game generated: /Main/LLM-PTG/Code/Playground/tw_games/game.ulx\n"
     ]
    }
   ],
   "source": [
    "!tw-make custom --world-size 2 --quest-length 3 --nb-objects 10 --output tw_games/game.ulx -f -v --seed 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1d0ab23-528f-41a9-aa8a-299812307a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tw-v15\n"
     ]
    }
   ],
   "source": [
    "import textworld.gym\n",
    "env_id = textworld.gym.register_game('tw_games/game.ulx')\n",
    "print(env_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed9baab3-4354-4bf5-b4ba-4ca79ddc82c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = textworld.gym.make(env_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af509bcc-64f6-4b56-93ff-02ebc38149a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "                    ________  ________  __    __  ________        \n",
      "                   |        \\|        \\|  \\  |  \\|        \\       \n",
      "                    \\$$$$$$$$| $$$$$$$$| $$  | $$ \\$$$$$$$$       \n",
      "                      | $$   | $$__     \\$$\\/  $$   | $$          \n",
      "                      | $$   | $$  \\     >$$  $$    | $$          \n",
      "                      | $$   | $$$$$    /  $$$$\\    | $$          \n",
      "                      | $$   | $$_____ |  $$ \\$$\\   | $$          \n",
      "                      | $$   | $$     \\| $$  | $$   | $$          \n",
      "                       \\$$    \\$$$$$$$$ \\$$   \\$$    \\$$          \n",
      "              __       __   ______   _______   __        _______  \n",
      "             |  \\  _  |  \\ /      \\ |       \\ |  \\      |       \\ \n",
      "             | $$ / \\ | $$|  $$$$$$\\| $$$$$$$\\| $$      | $$$$$$$\\\n",
      "             | $$/  $\\| $$| $$  | $$| $$__| $$| $$      | $$  | $$\n",
      "             | $$  $$$\\ $$| $$  | $$| $$    $$| $$      | $$  | $$\n",
      "             | $$ $$\\$$\\$$| $$  | $$| $$$$$$$\\| $$      | $$  | $$\n",
      "             | $$$$  \\$$$$| $$__/ $$| $$  | $$| $$_____ | $$__/ $$\n",
      "             | $$$    \\$$$ \\$$    $$| $$  | $$| $$     \\| $$    $$\n",
      "              \\$$      \\$$  \\$$$$$$  \\$$   \\$$ \\$$$$$$$$ \\$$$$$$$ \n",
      "\n",
      "You are now playing a fast paced round of TextWorld! Here is your task for today. First of all, you could, like, try to travel east. After that, take the binder from the locker. With the binder, place the binder on the mantelpiece. Alright, thanks!\n",
      "\n",
      "-= Vault =-\n",
      "You've just walked into a vault. You begin to take stock of what's here.\n",
      "\n",
      "An open safe is here. What a letdown! The safe is empty! You make out a shelf. But the thing hasn't got anything on it. What, you think everything in TextWorld should have stuff on it?\n",
      "\n",
      "You don't like doors? Why not try going east, that entranceway is unguarded.\n",
      "\n",
      "\n",
      "go east\n",
      "Inference took 0.999 seconds\n",
      "> go east\n",
      "\n",
      "-= Office =-\n",
      "You arrive in an office. An ordinary one.\n",
      "\n",
      "You can make out a locker. The locker contains a binder. You see a case. The case is empty, what a horrible day! You lean against the wall, inadvertently pressing a secret button. The wall opens up to reveal a mantelpiece. You wonder idly who left that here. The mantelpiece is standard. The mantelpiece appears to be empty. If you haven't noticed it already, there seems to be something there by the wall, it's a table. Unfortunately, there isn't a thing on it. Hm. Oh well\n",
      "\n",
      "There is an exit to the west. Don't worry, it is unguarded.\n",
      "\n",
      "\n",
      "place binder on mantelpiece\n",
      "Inference took 1.426 seconds\n",
      "> place binder on mantelpiece\n",
      "That's not a verb I recognise.\n",
      "\n",
      "\n",
      "take binder from locker\n",
      "Inference took 1.220 seconds\n",
      "> take binder from locker\n",
      "You take the binder from the locker.\n",
      "\n",
      "\n",
      "place binder on mantelpiece\n",
      "Inference took 1.469 seconds\n",
      "> place binder on mantelpiece\n",
      "That's not a verb I recognise.\n",
      "\n",
      "\n",
      "put binder on mantelpiece\n",
      "Inference took 1.472 seconds\n",
      "\u001b[33m> put binder on mantelpiece\u001b[0m\n",
      "You put the binder on the mantelpiece.\n",
      "\n",
      "\n",
      "Your score has just gone up by one point.\n",
      "\n",
      "\n",
      "                               *** The End ***\n",
      "\n",
      "You scored 1 out of a possible 1, in 4 turns.\n",
      "\n",
      "\n",
      "Would you like to RESTART, RESTORE a saved game, QUIT or UNDO the last command?\n",
      ">\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'moves'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Quit the game.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPlayed \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m steps, scoring \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m points.\u001b[39m\u001b[33m\"\u001b[39m.format(\u001b[43mgame_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmoves\u001b[49m, game_state.score))\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'moves'"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an assistant playing a textual game.\n",
    "You analyze the information given carefully and reply in the form \\\"verb noun\\\", e.g. \\\"open box\\\" or \\\"take key\\\".\n",
    "/no_think\n",
    "\"\"\"\n",
    "context = token_system + system_prompt + token_endofturn\n",
    "\n",
    "try:\n",
    "    done = False\n",
    "    env.reset()\n",
    "    while not done:\n",
    "        game_status = env.render(mode=\"text\")\n",
    "        print(game_status)\n",
    "        context += token_user + game_status + token_endofturn + token_assistant\n",
    "        \n",
    "        start = time.time()    \n",
    "        input_ids = tokenizer.encode(\n",
    "            context,\n",
    "            return_tensors=\"pt\")\n",
    "        \n",
    "        output = model.generate(\n",
    "            input_ids.to(\"cuda\"),\n",
    "            max_new_tokens=100,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "        response = tokenizer.decode(output[0, input_ids.shape[1]:], skip_special_tokens=True).replace(\"<think>\", \"\").replace(\"</think>\", \"\").strip(\"\\n\")\n",
    "        context += response + token_endofturn\n",
    "        print(response)\n",
    "        \n",
    "        end = time.time()\n",
    "        print(f\"Inference took {(end - start):.3f} seconds\")\n",
    "        \n",
    "        command = response if len(response.split()) <= 5 else \"look around\"\n",
    "        game_state, score, done, infos = env.step(command)\n",
    "\n",
    "    env.render()  # Final message.\n",
    "except KeyboardInterrupt:\n",
    "    pass  # Quit the game.\n",
    "\n",
    "print(\"Played {} steps, scoring {} points.\".format(game_state.moves, game_state.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a68d4-15a9-444c-b66c-a646f0ea571d",
   "metadata": {},
   "source": [
    "# Test with cumulative score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "190ead67-f292-4d65-9d6a-93bf3cc06159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import textworld\n",
    "\n",
    "# create a game\n",
    "!tw-make tw-simple --rewards dense --goal detailed --seed 18 --test --silent -f --output games/test-game.z8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1d4868b5-ffea-41e2-a50e-45034af6980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a play function for playing + recording scores\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import textworld.gym\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def play(agent, path, max_step=100, nb_episodes=10, verbose=True):\n",
    "    torch.manual_seed(46)  # For reproducibility when using action sampling.\n",
    "\n",
    "    infos_to_request = agent.infos_to_request\n",
    "    infos_to_request.max_score = True  # Needed to normalize the scores.\n",
    "\n",
    "    gamefiles = [path]\n",
    "    if os.path.isdir(path):\n",
    "        gamefiles = glob(os.path.join(path, \"*.z8\"))\n",
    "\n",
    "    env_id = textworld.gym.register_games(gamefiles,\n",
    "                                          request_infos=infos_to_request,\n",
    "                                          max_episode_steps=max_step)\n",
    "    env = textworld.gym.make(env_id)  # Create a Gym environment to play the text game.\n",
    "    if verbose:\n",
    "        if os.path.isdir(path):\n",
    "            print(os.path.dirname(path), end=\"\")\n",
    "        else:\n",
    "            print(os.path.basename(path), end=\"\")\n",
    "\n",
    "    # Collect some statistics: nb_steps, final reward.\n",
    "    avg_moves, avg_scores, avg_norm_scores = [], [], []\n",
    "    for no_episode in range(nb_episodes):\n",
    "        obs, infos = env.reset()  # Start new episode.\n",
    "\n",
    "        score = 0\n",
    "        done = False\n",
    "        nb_moves = 0\n",
    "        while not done:\n",
    "            command = agent.act(obs, score, done, infos)\n",
    "            obs, score, done, infos = env.step(command)\n",
    "            nb_moves += 1\n",
    "\n",
    "        agent.act(obs, score, done, infos)  # Let the agent know the game is done.\n",
    "\n",
    "        if verbose:\n",
    "            print(\".\", end=\"\")\n",
    "        avg_moves.append(nb_moves)\n",
    "        avg_scores.append(score)\n",
    "        avg_norm_scores.append(score / infos[\"max_score\"])\n",
    "\n",
    "    env.close()\n",
    "    if verbose:\n",
    "        if os.path.isdir(path):\n",
    "            msg = \"  \\tavg. steps: {:5.1f}; avg. normalized score: {:4.1f} / {}.\"\n",
    "            print(msg.format(np.mean(avg_moves), np.mean(avg_norm_scores), 1))\n",
    "        else:\n",
    "            msg = \"  \\tavg. steps: {:5.1f}; avg. score: {:4.1f} / {}.\"\n",
    "            print(msg.format(np.mean(avg_moves), np.mean(avg_scores), infos[\"max_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1c6f3dca-1b16-4dba-afb9-e97c20319b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create agents\n",
    "\n",
    "from typing import Mapping, Any\n",
    "import numpy as np\n",
    "import textworld.gym\n",
    "\n",
    "class RandomAgent(textworld.gym.Agent):\n",
    "    \"\"\" Agent that randomly selects a command from the admissible ones. \"\"\"\n",
    "    def __init__(self, seed=1234):\n",
    "        self.seed = seed\n",
    "        self.rng = np.random.RandomState(self.seed)\n",
    "\n",
    "    @property\n",
    "    def infos_to_request(self) -> textworld.EnvInfos:\n",
    "        return textworld.EnvInfos(admissible_commands=True)\n",
    "\n",
    "    def act(self, obs: str, score: int, done: bool, infos: Mapping[str, Any]) -> str:\n",
    "        return self.rng.choice(infos[\"admissible_commands\"])\n",
    "\n",
    "class HFAgent(textworld.gym.Agent):\n",
    "    \"\"\"LLM from HuggingFace that acts as an agent.\"\"\"\n",
    "    model = None\n",
    "    tokenizer = None\n",
    "    context = \"\"\n",
    "    token_system = \"<|im_start|>system\\n\"\n",
    "    token_endofturn = \"<|im_end|>\\n\"\n",
    "    token_user = \"<|im_start|>user\\n\"\n",
    "    token_assistant = \"<|im_start|>assistant\\n\"\n",
    "    system_prompt = \"\"\"\n",
    "You are an assistant playing a textual game.\n",
    "The user gives you information on the environment and you reply exclusively in the form \\\"verb noun\\\", like \\\"open box\\\" or \\\"take key\\\".\n",
    "/no_think\n",
    "\"\"\"\n",
    "    first_move = False\n",
    "    \n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.initialize_context()\n",
    "\n",
    "    def initialize_context(self):\n",
    "        self.context = self.token_system + self.system_prompt + self.token_endofturn\n",
    "        self.first_move = True\n",
    "\n",
    "    @property\n",
    "    def infos_to_request(self) -> textworld.EnvInfos:\n",
    "        return textworld.EnvInfos(admissible_commands=True)\n",
    "\n",
    "    def act(self, obs: str, score: int, done: bool, infos: Mapping[str, Any]) -> str:\n",
    "\n",
    "        if done:\n",
    "            self.initialize_context() # resets context\n",
    "        if first_move:\n",
    "            first_move = False\n",
    "            return \"help\"\n",
    "        \n",
    "        try:\n",
    "            self.context += self.token_user + obs + self.token_endofturn\n",
    "            self.context += self.token_assistant # induces model to generate answer\n",
    "            \n",
    "            input_ids = self.tokenizer.encode(\n",
    "                self.context,\n",
    "                return_tensors = \"pt\")\n",
    "            \n",
    "            generated_ids = self.model.generate(\n",
    "                input_ids.to(\"cuda\"),\n",
    "                max_new_tokens = 100,\n",
    "                eos_token_id = self.tokenizer.eos_token_id\n",
    "                )\n",
    "            output_ids = generated_ids[0][len(input_ids[0]):].tolist() \n",
    "            \n",
    "            # parsing thinking content\n",
    "            try:\n",
    "                # index finding </think>\n",
    "                index = len(output_ids) - output_ids[::-1].index(think_command_id)\n",
    "            except ValueError:\n",
    "                index = 0\n",
    "            response = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "            \n",
    "            self.context += response + self.token_endofturn\n",
    "\n",
    "            if len(response.split()) <= 6:\n",
    "                command = response\n",
    "            else:\n",
    "                command = \"look\"\n",
    "                print(\"looking around...\")\n",
    "            return command\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            pass  # Try stopping the game prematurely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a91dec8e-5c85-4217-821b-8da0d8fbd9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-game.z8..........  \tavg. steps: 100.0; avg. score:  4.2 / 10.\n"
     ]
    }
   ],
   "source": [
    "# make the random agent play\n",
    "nb_episodes = 10\n",
    "max_steps = 50\n",
    "\n",
    "play(RandomAgent(), \"./games/test-game.z8\", max_steps = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "044be42e-557c-49d4-bbc3-17a911841690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-game.z8..........  \tavg. steps: 100.0; avg. score:  1.2 / 10.\n",
      "--- Model took 35.755 min to play 10 games\n"
     ]
    }
   ],
   "source": [
    "# make Qwen play\n",
    "\n",
    "start = time.time()\n",
    "play(HFAgent(model, tokenizer), \"./games/test-game.z8\", max_steps=max_steps, nb_episodes=nb_episodes)\n",
    "end = time.time()\n",
    "print(f\"Model took {((end - start)/60):.3f} min to play {nb_episodes} games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6218fd2a-e5b0-4d05-b17c-4ff1e92ca057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
