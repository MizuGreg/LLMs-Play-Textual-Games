{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29df1566",
   "metadata": {},
   "source": [
    "# Self-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7f88b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import textworld\n",
    "import textworld.gym\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "from typing import Mapping, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f499211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import accelerate\n",
    "torch.set_default_device('cuda')\n",
    "torch.cuda.device(\"cuda\")\n",
    "# torch.backends.cuda.matmul.allow_tf32 = True\n",
    "# torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04dfd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-4B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219eb39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4403d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.hf_device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7c46f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tw-make tw-simple --rewards dense --goal detailed --seed 18 --test --silent -f --output games/test-game.z8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681b294b",
   "metadata": {},
   "source": [
    "## Play function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb66068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(agent, path, max_steps=100, n_episodes=10, verbose=True):\n",
    "    torch.manual_seed(46)  # For reproducibility when using action sampling.\n",
    "\n",
    "    infos_to_request = agent.infos_to_request\n",
    "    infos_to_request.max_score = True  # Needed to normalize the scores.\n",
    "\n",
    "    gamefiles = [path]\n",
    "    if os.path.isdir(path):\n",
    "        gamefiles = glob(os.path.join(path, \"*.z8\"))\n",
    "\n",
    "    env_id = textworld.gym.register_games(gamefiles,\n",
    "                                          request_infos=infos_to_request,\n",
    "                                          max_episode_steps=max_steps)\n",
    "    env = textworld.gym.make(env_id)  # Create a Gym environment to play the text game.\n",
    "    if verbose:\n",
    "        if os.path.isdir(path):\n",
    "            print(os.path.dirname(path), end=\"\")\n",
    "        else:\n",
    "            print(os.path.basename(path), end=\"\")\n",
    "\n",
    "    # Collect some statistics: nb_steps, final reward.\n",
    "    avg_moves, avg_scores, avg_norm_scores = [], [], []\n",
    "    for no_episode in range(n_episodes):\n",
    "        obs, infos = env.reset()  # Start new episode.\n",
    "\n",
    "        score = 0\n",
    "        done = False\n",
    "        nb_moves = 0\n",
    "        while not done:\n",
    "            command = agent.act(obs, score, done, infos)\n",
    "            obs, score, done, infos = env.step(command)\n",
    "            nb_moves += 1\n",
    "\n",
    "        agent.act(obs, score, done, infos)  # Let the agent know the game is done.\n",
    "\n",
    "        if verbose:\n",
    "            print(\".\", end=\"\")\n",
    "        avg_moves.append(nb_moves)\n",
    "        avg_scores.append(score)\n",
    "        avg_norm_scores.append(score / infos[\"max_score\"])\n",
    "\n",
    "    env.close()\n",
    "    if verbose:\n",
    "        if os.path.isdir(path):\n",
    "            msg = \"  \\tavg. steps: {:5.1f}; avg. normalized score: {:4.1f} / {}.\"\n",
    "            print(msg.format(np.mean(avg_moves), np.mean(avg_norm_scores), 1))\n",
    "        else:\n",
    "            msg = \"  \\tavg. steps: {:5.1f}; avg. score: {:4.1f} / {}.\"\n",
    "            print(msg.format(np.mean(avg_moves), np.mean(avg_scores), infos[\"max_score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9722b791",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e263b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(textworld.gym.Agent):\n",
    "    \"\"\" Agent that randomly selects a command from the admissible ones. \"\"\"\n",
    "    def __init__(self, seed=1234):\n",
    "        self.seed = seed\n",
    "        self.rng = np.random.RandomState(self.seed)\n",
    "\n",
    "    @property\n",
    "    def infos_to_request(self) -> textworld.EnvInfos:\n",
    "        return textworld.EnvInfos(admissible_commands=True)\n",
    "\n",
    "    def act(self, obs: str, score: int, done: bool, infos: Mapping[str, Any]) -> str:\n",
    "        return self.rng.choice(infos[\"admissible_commands\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ea048",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMAgent(textworld.gym.Agent):\n",
    "    \"\"\"LLM from HuggingFace that acts as an agent.\"\"\"\n",
    "    model = None\n",
    "    tokenizer = None\n",
    "    context = \"\"\n",
    "\n",
    "    id_token_close_think = 151668 # </think>\n",
    "    token_system = \"<|im_start|>system\\n\"\n",
    "    token_endofturn = \"<|im_end|>\\n\"\n",
    "    token_user = \"<|im_start|>user\\n\"\n",
    "    token_assistant = \"<|im_start|>assistant\\n\"\n",
    "    system_prompt = \"\"\"\n",
    "You are an assistant playing a textual game.\n",
    "The user gives you information on the environment and you reply exclusively in the form \\\"verb noun\\\", like \\\"open box\\\" or \\\"take key\\\".\n",
    "/no_think\n",
    "\"\"\"\n",
    "    first_move = False\n",
    "    \n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.initialize_context()\n",
    "\n",
    "    def initialize_context(self):\n",
    "        self.context = self.token_system + self.system_prompt + self.token_endofturn\n",
    "        self.first_move = True\n",
    "\n",
    "    @property\n",
    "    def infos_to_request(self) -> textworld.EnvInfos:\n",
    "        return textworld.EnvInfos(admissible_commands=True)\n",
    "\n",
    "    def act(self, obs: str, score: int, done: bool, infos: Mapping[str, Any]) -> str:\n",
    "\n",
    "        if done:\n",
    "            self.initialize_context() # resets context\n",
    "        if self.first_move:\n",
    "            self.first_move = False\n",
    "            return \"help\"\n",
    "        \n",
    "        try:\n",
    "            self.context += self.token_user + obs + self.token_endofturn\n",
    "            self.context += self.token_assistant # induces model to generate answer\n",
    "            \n",
    "            input_ids = self.tokenizer.encode(\n",
    "                self.context,\n",
    "                return_tensors = \"pt\")\n",
    "            \n",
    "            generated_ids = self.model.generate(\n",
    "                input_ids.to(\"cuda\"),\n",
    "                max_new_tokens = 100,\n",
    "                eos_token_id = self.tokenizer.eos_token_id\n",
    "                )\n",
    "            output_ids = generated_ids[0][len(input_ids[0]):].tolist() \n",
    "            \n",
    "            # parsing thinking content\n",
    "            try:\n",
    "                # index finding </think>\n",
    "                index = len(output_ids) - output_ids[::-1].index(self.id_token_close_think)\n",
    "            except ValueError:\n",
    "                index = 0\n",
    "            response = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "            \n",
    "            self.context += response + self.token_endofturn\n",
    "\n",
    "            if len(response.split()) <= 10:\n",
    "                command = response\n",
    "            else: # more than 10 words, output is surely wrong\n",
    "                command = \"look\"\n",
    "            return command\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            pass  # Try stopping the game prematurely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541dfd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMAgentSelfEvaluate(LLMAgent):\n",
    "    \"\"\"LLM from HuggingFace that acts as an agent. It self-evaluates its status and moves.\"\"\"\n",
    "\n",
    "    selfeval_turn_counter = 0\n",
    "    selfeval_turns = 5\n",
    "    handheld = True\n",
    "\n",
    "    def __init__(self, model, tokenizer, selfeval_turns = 5, handheld = True):\n",
    "        \"\"\"Initialization function.\n",
    "        selfeval_turns: how many turns should pass between a self-evaluation and the next one.\n",
    "        handheld: if this is set to True there are a few simple changes in the function that make it easier for the LLM to understand and correct its course\n",
    "        \"\"\"\n",
    "        super.__init__(self, model, tokenizer)\n",
    "        self.selfeval_turns = selfeval_turns\n",
    "        self.handheld = handheld\n",
    "\n",
    "    def act(self, obs: str, score: int, done: bool, infos: Mapping[str, Any]) -> str:\n",
    "\n",
    "        if done:\n",
    "            self.initialize_context() # resets context\n",
    "            print(\"\\nDone!\\n\")\n",
    "\n",
    "        if self.first_move and self.handheld:\n",
    "            self.first_move = False\n",
    "            return \"help\"\n",
    "        \n",
    "        try:\n",
    "            self.context += self.token_user + obs + self.token_endofturn\n",
    "            self.context += self.token_assistant # induces model to generate answer\n",
    "            \n",
    "            input_ids = self.tokenizer.encode(\n",
    "                self.context,\n",
    "                return_tensors = \"pt\")\n",
    "            \n",
    "            generated_ids = self.model.generate(\n",
    "                input_ids.to(\"cuda\"),\n",
    "                max_new_tokens = 100,\n",
    "                eos_token_id = self.tokenizer.eos_token_id\n",
    "                )\n",
    "            output_ids = generated_ids[0][len(input_ids[0]):].tolist() \n",
    "            \n",
    "            # parsing thinking content\n",
    "            try:\n",
    "                # index finding </think>\n",
    "                index = len(output_ids) - output_ids[::-1].index(self.id_token_close_think)\n",
    "            except ValueError:\n",
    "                index = 0\n",
    "            response = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "            \n",
    "            self.context += response + self.token_endofturn\n",
    "\n",
    "            if len(response.split()) <= 10 or not self.handheld:\n",
    "                command = response\n",
    "            else: # more than 10 words, output is surely wrong\n",
    "                command = \"look\"\n",
    "            return command\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            pass  # Try stopping the game prematurely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa9f3f",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497c8b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 100\n",
    "n_episodes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c42adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "play(LLMAgentSelfEvaluate(model, tokenizer), \"./games/test-game.z8\", max_steps=max_steps, n_episodes=n_episodes)\n",
    "end = time.time()\n",
    "print(f\"Model took {((end - start)/60):.3f} min to play {n_episodes} games\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
