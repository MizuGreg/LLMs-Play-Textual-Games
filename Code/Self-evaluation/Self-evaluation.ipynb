{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29df1566",
   "metadata": {},
   "source": [
    "# Self-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065c7d55-8c76-4537-a0f7-b2a917573158",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7f88b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import textworld\n",
    "import textworld.gym\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "from typing import Mapping, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f499211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x7ee6759d70e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import accelerate\n",
    "torch.set_default_device('cuda')\n",
    "torch.cuda.device(\"cuda\")\n",
    "# torch.backends.cuda.matmul.allow_tf32 = True\n",
    "# torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b04dfd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-4B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219eb39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aefaa7c973344f1bdde0e7f05a3cdf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c4403d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0}\n"
     ]
    }
   ],
   "source": [
    "print(model.hf_device_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681b294b",
   "metadata": {},
   "source": [
    "## Play function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cb66068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(agent, path, max_steps=100, n_episodes=10, verbose=True):\n",
    "    torch.manual_seed(46)  # For reproducibility when using action sampling.\n",
    "\n",
    "    infos_to_request = agent.infos_to_request\n",
    "    infos_to_request.max_score = True  # Needed to normalize the scores.\n",
    "\n",
    "    gamefiles = [path]\n",
    "    if os.path.isdir(path):\n",
    "        gamefiles = glob(os.path.join(path, \"*.z8\"))\n",
    "\n",
    "    env_id = textworld.gym.register_games(gamefiles,\n",
    "                                          request_infos=infos_to_request,\n",
    "                                          max_episode_steps=max_steps)\n",
    "    env = textworld.gym.make(env_id)  # Create a Gym environment to play the text game.\n",
    "    if verbose:\n",
    "        if os.path.isdir(path):\n",
    "            print(os.path.dirname(path), end=\"\")\n",
    "        else:\n",
    "            print(os.path.basename(path), end=\"\")\n",
    "\n",
    "    # Collect some statistics: nb_steps, final reward.\n",
    "    avg_moves, avg_scores, avg_norm_scores = [], [], []\n",
    "    for no_episode in range(n_episodes):\n",
    "        obs, infos = env.reset()  # Start new episode.\n",
    "\n",
    "        score = 0\n",
    "        done = False\n",
    "        nb_moves = 0\n",
    "        while not done:\n",
    "            command = agent.act(obs, score, done, infos)\n",
    "            obs, score, done, infos = env.step(command)\n",
    "            nb_moves += 1\n",
    "\n",
    "        agent.act(obs, score, done, infos)  # Let the agent know the game is done.\n",
    "\n",
    "        if verbose:\n",
    "            print(\".\", end=\"\")\n",
    "        avg_moves.append(nb_moves)\n",
    "        avg_scores.append(score)\n",
    "        avg_norm_scores.append(score / infos[\"max_score\"])\n",
    "\n",
    "    env.close()\n",
    "    if verbose:\n",
    "        if os.path.isdir(path):\n",
    "            msg = \"  \\tavg. steps: {:5.1f}; avg. normalized score: {:4.1f} / {}.\"\n",
    "            print(msg.format(np.mean(avg_moves), np.mean(avg_norm_scores), 1))\n",
    "            if len(avg_moves) > 1:\n",
    "                print(f\"Detailed steps: {avg_moves}\\t Detailed normalized scores: {avg_norm_scores}\")\n",
    "        else:\n",
    "            msg = \"  \\tavg. steps: {:5.1f}; avg. score: {:4.1f} / {}.\"\n",
    "            print(msg.format(np.mean(avg_moves), np.mean(avg_scores), infos[\"max_score\"]))\n",
    "            if len(avg_moves) > 1:\n",
    "                print(f\"Detailed steps: {avg_moves}\\t Detailed scores: {avg_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9722b791",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e263b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(textworld.gym.Agent):\n",
    "    \"\"\" Agent that randomly selects a command from the admissible ones. \"\"\"\n",
    "    def __init__(self, seed=1234):\n",
    "        self.seed = seed\n",
    "        self.rng = np.random.RandomState(self.seed)\n",
    "\n",
    "    @property\n",
    "    def infos_to_request(self) -> textworld.EnvInfos:\n",
    "        return textworld.EnvInfos(admissible_commands=True)\n",
    "\n",
    "    def act(self, obs: str, score: int, done: bool, infos: Mapping[str, Any]) -> str:\n",
    "        return self.rng.choice(infos[\"admissible_commands\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19ea048",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMAgent(textworld.gym.Agent):\n",
    "    \"\"\"LLM from HuggingFace that acts as an agent.\"\"\"\n",
    "    model = None\n",
    "    tokenizer = None\n",
    "    context = \"\"\n",
    "\n",
    "    token_think = \"/think\"\n",
    "    token_nothink = \"/no_think\"\n",
    "    id_token_open_think = None # <think> . TODO find it\n",
    "    id_token_close_think = 151668 # </think>\n",
    "    token_system = \"<|im_start|>system\\n\"\n",
    "    token_endofturn = \"<|im_end|>\\n\"\n",
    "    token_user = \"<|im_start|>user\\n\"\n",
    "    token_assistant = \"<|im_start|>assistant\\n\"\n",
    "    system_prompt = \"\"\"\n",
    "You are an assistant playing a textual game.\n",
    "The user gives you information on the environment and you reply exclusively in the form \\\"verb noun\\\", like \\\"open box\\\" or \\\"take key\\\".\n",
    "/no_think\n",
    "\"\"\"\n",
    "    first_move = False\n",
    "    \n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.initialize_context()\n",
    "\n",
    "    def initialize_context(self):\n",
    "        self.context = self.token_system + self.system_prompt + self.token_endofturn\n",
    "        self.first_move = True\n",
    "\n",
    "    @property\n",
    "    def infos_to_request(self) -> textworld.EnvInfos:\n",
    "        return textworld.EnvInfos(admissible_commands=True)\n",
    "\n",
    "    def act(self, obs: str, score: int, done: bool, infos: Mapping[str, Any]) -> str:\n",
    "\n",
    "        if done:\n",
    "            self.initialize_context() # resets context\n",
    "            return \":)\"\n",
    "            \n",
    "        if self.first_move:\n",
    "            self.first_move = False\n",
    "            return \"help\"\n",
    "        \n",
    "        try:\n",
    "            self.context += self.token_user + obs + self.token_endofturn\n",
    "            self.context += self.token_assistant # induces model to generate answer\n",
    "            \n",
    "            input_ids = self.tokenizer.encode(\n",
    "                self.context,\n",
    "                return_tensors = \"pt\")\n",
    "            \n",
    "            generated_ids = self.model.generate(\n",
    "                input_ids.to(\"cuda\"),\n",
    "                max_new_tokens = 100,\n",
    "                eos_token_id = self.tokenizer.eos_token_id\n",
    "                )\n",
    "            output_ids = generated_ids[0][len(input_ids[0]):].tolist() \n",
    "            \n",
    "            # parsing thinking content\n",
    "            try:\n",
    "                # index finding </think>\n",
    "                index = len(output_ids) - output_ids[::-1].index(self.id_token_close_think)\n",
    "            except ValueError:\n",
    "                index = 0\n",
    "            response = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "            \n",
    "            self.context += response + self.token_endofturn\n",
    "\n",
    "            if len(response.split()) <= 10:\n",
    "                command = response\n",
    "            else: # more than 10 words, output is surely wrong\n",
    "                command = \"look\"\n",
    "            return command\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            pass  # Try stopping the game prematurely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "541dfd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMAgentSelfEvaluate(LLMAgent):\n",
    "    \"\"\"LLM from HuggingFace that acts as an agent. It self-evaluates its status and moves.\"\"\"\n",
    "\n",
    "    selfeval_turn_counter = 0\n",
    "    selfeval_turns = 5\n",
    "    handheld = True\n",
    "    verbose = False\n",
    "    reads_own_reasoning = False\n",
    "\n",
    "    def __init__(self, model, tokenizer, selfeval_turns = 5, handheld = True, verbose = False, reads_own_reasoning = False):\n",
    "        \"\"\"Initialization function.\n",
    "        selfeval_turns: how many turns should pass between a self-evaluation and the next one.\n",
    "        handheld: if this is set to True there are a few simple changes in the function that make it easier for the LLM to understand and correct its course\n",
    "        \"\"\"\n",
    "        super().__init__(model, tokenizer)\n",
    "        self.selfeval_turns = selfeval_turns\n",
    "        self.handheld = handheld\n",
    "        self.verbose = verbose\n",
    "        self.reads_own_reasoning = reads_own_reasoning\n",
    "\n",
    "    def initialize_context(self):\n",
    "        super().initialize_context()\n",
    "        self.selfeval_turn_counter = 0\n",
    "\n",
    "    def generate_response(self, think=False, max_new_tokens = 30000):\n",
    "        input_ids = self.tokenizer.encode(\n",
    "                self.context,\n",
    "                return_tensors = \"pt\")\n",
    "            \n",
    "        generated_ids = self.model.generate(\n",
    "            input_ids.to(\"cuda\"),\n",
    "            max_new_tokens = max_new_tokens,\n",
    "            eos_token_id = self.tokenizer.eos_token_id\n",
    "            )\n",
    "        output_ids = generated_ids[0][len(input_ids[0]):].tolist() \n",
    "        # parsing thinking content\n",
    "        try:\n",
    "            # index finding </think>\n",
    "            index = len(output_ids) - output_ids[::-1].index(self.id_token_close_think)\n",
    "        except ValueError:\n",
    "            index = 0\n",
    "        if think:\n",
    "            thinking_response = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "            response = tokenizer.decode(output_ids[index:], skip_special_tokens=True).replace(\"<think>\", \"\").replace(\"</think>\", \"\").strip(\"\\n\")\n",
    "            return (thinking_response, response)\n",
    "        else:\n",
    "            response = tokenizer.decode(output_ids[index:], skip_special_tokens=True).replace(\"<think>\", \"\").replace(\"</think>\", \"\").strip(\"\\n\")\n",
    "            return response\n",
    "\n",
    "    def act(self, obs: str, score: int, done: bool, infos: Mapping[str, Any]) -> str:\n",
    "        if done:\n",
    "            self.initialize_context() # resets context\n",
    "            return \":)\"\n",
    "        \n",
    "        if self.selfeval_turn_counter == self.selfeval_turns: # time for self-evaluation\n",
    "            self.selfeval_turn_counter = 0 # reset counter\n",
    "            return self.self_evaluation(obs)\n",
    "            \n",
    "        try:\n",
    "            self.context += self.token_user + obs + self.token_endofturn\n",
    "            self.context += self.token_assistant # induces model to generate answer\n",
    "\n",
    "            if self.first_move and self.handheld:\n",
    "                self.first_move = False\n",
    "                command = \"help\"\n",
    "            else:\n",
    "                response = self.generate_response()\n",
    "                if len(response.split()) <= 10 or not self.handheld:\n",
    "                    command = response\n",
    "                else: # more than 10 words, output is surely wrong\n",
    "                    command = \"look\"\n",
    "            \n",
    "            self.context += command + self.token_endofturn\n",
    "\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(\"GAME ++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "                print(obs)\n",
    "                print(\"AGENT -------------------------------------------------\")\n",
    "                print(command)\n",
    "\n",
    "            self.selfeval_turn_counter += 1\n",
    "            return command\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            pass  # Try stopping the game prematurely.\n",
    "\n",
    "    def self_evaluation(self, obs) -> str :\n",
    "        self_evaluation_prompt = \"\"\"\n",
    "Do you think you're making the right actions in the game? Do you think you're close to reaching the original goal? Think about it.\n",
    "\"\"\"\n",
    "        self.context += self.token_user + obs + self_evaluation_prompt + self.token_think + self.token_endofturn # induce thinking\n",
    "        self.context += self.token_assistant\n",
    "        \n",
    "        (thinking_response, response) = self.generate_response(think=True)\n",
    "        if self.verbose:\n",
    "            print(\"GAME ++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "            print(obs + self_evaluation_prompt)\n",
    "            print(\"SELF-EVALUATION: +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\")\n",
    "            print(thinking_response + response + self.token_nothink)\n",
    "\n",
    "        if self.reads_own_reasoning:\n",
    "            self.context += thinking_response + response + self.token_nothink + self.token_endofturn\n",
    "        else:\n",
    "            self.context += response + self.token_nothink + self.token_endofturn\n",
    "\n",
    "        if len(response.split()) <= 10 or not self.handheld:\n",
    "            command = response\n",
    "        else: # more than 10 words, output is surely wrong\n",
    "            command = \"look\"\n",
    "        self.selfeval_turn_counter += 1\n",
    "        return command\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa9f3f",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "497c8b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 100\n",
    "n_episodes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfc16341-716b-4458-abe4-c45e73775a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tw-make tw-simple --rewards dense --goal detailed --seed 8 --test --silent -f --output games/test-game.z8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20c42adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-game.z8.  \tavg. steps:  38.0; avg. score: 10.0 / 10.\n",
      "Model took 1.865 min to play 1 games\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "play(LLMAgentSelfEvaluate(model, tokenizer, selfeval_turns = 5, handheld=True, verbose=False), \"./games/test-game.z8\", max_steps=max_steps, n_episodes=n_episodes)\n",
    "end = time.process_time()\n",
    "print(f\"Model took {((end - start)/60):.3f} min to play {n_episodes} games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79209b0b-77c3-42ba-83fd-a821b8747d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-game.z8.  \tavg. steps:  33.0; avg. score: 10.0 / 10.\n",
      "Model took 1.230 min to play 1 games\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "play(LLMAgentSelfEvaluate(model, tokenizer, selfeval_turns = 5, handheld=False, verbose=False), \"./games/test-game.z8\", max_steps=max_steps, n_episodes=n_episodes)\n",
    "end = time.process_time()\n",
    "print(f\"Model took {((end - start)/60):.3f} min to play {n_episodes} games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ead3ea4-481b-457f-b885-3962b57e1836",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.process_time()\n",
    "play(LLMAgentSelfEvaluate(model, tokenizer, selfeval_turns = 5, handheld=True, verbose=True, reads_own_reasoning=True), \"./games/test-game.z8\", max_steps=max_steps, n_episodes=n_episodes)\n",
    "end = time.process_time()\n",
    "print(f\"Model took {((end - start)/60):.3f} min to play {n_episodes} games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227389ed-6c42-42aa-b97f-6f3e6199afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.process_time()\n",
    "play(LLMAgentSelfEvaluate(model, tokenizer, selfeval_turns = 5, handheld=False, verbose=True), \"./games/test-game.z8\", max_steps=max_steps, n_episodes=n_episodes)\n",
    "end = time.process_time()\n",
    "print(f\"Model took {((end - start)/60):.3f} min to play {n_episodes} games\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5953dab9-3445-492d-8730-30a595f97309",
   "metadata": {},
   "source": [
    "# Treasure hunter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72653ca7-7007-42d7-aa4d-b194765efc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 100\n",
    "n_episodes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b56baae-2809-4e15-a3b4-feca0ea1ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tw-make tw-treasure_hunter --level 9 --seed 0 --silent -f --output games/test-treasure.z8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d49ed3d7-ec2a-43c7-aa25-6b5b5dc6583e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-treasure.z8.....  \tavg. steps:  38.2; avg. score:  0.0 / 1.\n",
      "Detailed steps: [20, 30, 14, 27, 100]\t Detailed scores: [0, 0, 0, 0, 0]\n",
      "Model took 5.845 min to play 5 games\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "play(LLMAgentSelfEvaluate(model, tokenizer, selfeval_turns = 5, handheld=False, verbose=False), \"./games/test-treasure.z8\", max_steps=max_steps, n_episodes=n_episodes)\n",
    "end = time.process_time()\n",
    "print(f\"Model took {((end - start)/60):.3f} min to play {n_episodes} games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc36f62c-21c4-45d2-bb66-6a84903dc4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-treasure.z8.....  \tavg. steps:   6.0; avg. score:  1.0 / 1.\n",
      "Detailed steps: [6, 6, 6, 6, 6]\t Detailed scores: [1, 1, 1, 1, 1]\n",
      "Model took 0.396 min to play 5 games\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "play(LLMAgentSelfEvaluate(model, tokenizer, selfeval_turns = 5, handheld=True, verbose=False), \"./games/test-treasure.z8\", max_steps=max_steps, n_episodes=n_episodes)\n",
    "end = time.process_time()\n",
    "print(f\"Model took {((end - start)/60):.3f} min to play {n_episodes} games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0769eef7-c1e8-4e8a-bc6e-4af2edf86ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.process_time()\n",
    "play(LLMAgentSelfEvaluate(model, tokenizer, selfeval_turns = 5, handheld=False, verbose=True), \"./games/test-treasure.z8\", max_steps=max_steps, n_episodes=n_episodes)\n",
    "end = time.process_time()\n",
    "print(f\"Model took {((end - start)/60):.3f} min to play {n_episodes} games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd78ee85-b55c-4bba-9d7e-e2e3eb83a768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
